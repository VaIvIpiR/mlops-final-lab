import os
import sagemaker
from sagemaker.workflow.pipeline import Pipeline
from sagemaker.workflow.steps import TrainingStep, CreateModelStep
from sagemaker.workflow.step_collections import RegisterModel
from sagemaker.workflow.parameters import ParameterInteger, ParameterString
from sagemaker.pytorch import PyTorch, PyTorchModel
from sagemaker.inputs import TrainingInput

# --- –í–ê–®–Ü –ù–û–í–Ü –†–ï–°–£–†–°–ò –ó TERRAFORM ---
TERRAFORM_BUCKET = "mlops-lab-terraform-vaivipir-data"
TERRAFORM_ROLE = "arn:aws:iam::584360834542:role/mlops-lab-terraform-role"

def get_pipeline(
    region,
    role=None,
    default_bucket=None,
    pipeline_name="NewsClassifierPipeline",
    model_package_group_name="NewsClassifierGroup",
    base_job_prefix="NewsClassifier"
):
    """
    –§—É–Ω–∫—Ü—ñ—è, —è–∫–∞ –ø–æ–≤–µ—Ä—Ç–∞—î –æ–±'—î–∫—Ç Pipeline.
    """
    sess = sagemaker.Session()
    
    # 1. –Ø–∫—â–æ –±–∞–∫–µ—Ç –Ω–µ –ø–µ—Ä–µ–¥–∞–ª–∏, –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ –Ω–∞—à –ù–û–í–ò–ô –∑ Terraform
    if default_bucket is None:
        default_bucket = TERRAFORM_BUCKET

    # 2. –ü–∞—Ä–∞–º–µ—Ç—Ä–∏ –ø–∞–π–ø–ª–∞–π–Ω—É
    training_instance_type = ParameterString(name="TrainingInstanceType", default_value="ml.m5.large")
    
    # 3. –í–∫–∞–∑—É—î–º–æ —à–ª—è—Ö –¥–æ –¥–∞–Ω–∏—Ö —É –ù–û–í–û–ú–£ –±–∞–∫–µ—Ç—ñ
    input_data = ParameterString(
        name="InputData", 
        default_value=f"s3://{default_bucket}/data/raw/"
    )
    
    epochs = ParameterInteger(name="Epochs", default_value=3)
    batch_size = ParameterInteger(name="BatchSize", default_value=8)

    # --- –ö—Ä–æ–∫ 1: –¢—Ä–µ–Ω—É–≤–∞–Ω–Ω—è ---
    estimator = PyTorch(
        entry_point='train_sagemaker.py',
        source_dir='./src', 
        role=role,
        framework_version='1.13',
        py_version='py39',
        instance_count=1,
        instance_type=training_instance_type,
        # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏ —É –Ω–æ–≤–∏–π –±–∞–∫–µ—Ç
        output_path=f"s3://{default_bucket}/NewsClassifier/training_jobs",
        hyperparameters={'epochs': epochs, 'batch-size': batch_size, 'learning-rate': 2e-5},
        environment={
            'MLFLOW_TRACKING_URI': 'https://dagshub.com/vaivipir/news-classifier.mlflow',
            'MLFLOW_TRACKING_USERNAME': 'vaivipir',
            'MLFLOW_TRACKING_PASSWORD': 'a38c18a9ac6a76a6d22f38feae7cc1e984dff094' 
        }
    )

    step_train = TrainingStep(
        name="BertTrainingStep",
        estimator=estimator,
        inputs={"training": TrainingInput(s3_data=input_data)}
    )

    # --- –ö—Ä–æ–∫ 2: –°—Ç–≤–æ—Ä–µ–Ω–Ω—è –º–æ–¥–µ–ª—ñ ---
    model = PyTorchModel(
        model_data=step_train.properties.ModelArtifacts.S3ModelArtifacts,
        role=role,
        entry_point='inference.py',
        source_dir='./src',
        framework_version='1.13',
        py_version='py39',
        sagemaker_session=sess
    )

    step_create_model = CreateModelStep(
        name="BertCreateModelStep",
        model=model,
        inputs=sagemaker.inputs.CreateModelInput(instance_type="ml.m5.large")
    )

    # --- –ö—Ä–æ–∫ 3: –†–µ—î—Å—Ç—Ä–∞—Ü—ñ—è ---
    step_register = RegisterModel(
        name="BertRegisterStep",
        estimator=estimator,
        model_data=step_train.properties.ModelArtifacts.S3ModelArtifacts,
        content_types=["application/json"],
        response_types=["application/json"],
        inference_instances=["ml.m5.large"],
        transform_instances=["ml.m5.large"],
        model_package_group_name=model_package_group_name,
        approval_status="PendingManualApproval"
    )

    # –ó–±–∏—Ä–∞—î–º–æ –ø–∞–π–ø–ª–∞–π–Ω
    pipeline = Pipeline(
        name=pipeline_name,
        parameters=[training_instance_type, input_data, epochs, batch_size],
        steps=[step_train, step_create_model, step_register]
    )
    
    return pipeline

if __name__ == "__main__":
    print("üöÄ Building pipeline using Terraform resources...")
    
    import sys
    
    # –ë–µ—Ä–µ–º–æ —Ä–æ–ª—å –∑ –µ–Ω–≤–∞–π—Ä–æ–Ω–º–µ–Ω—Ç—É (GitHub) –ê–ë–û –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ –Ω–æ–≤—É –∑ Terraform —è–∫ –¥–µ—Ñ–æ–ª—Ç
    role_arn = os.environ.get("SAGEMAKER_ROLE_ARN", TERRAFORM_ROLE)
    
    print(f"üîë Using Role: {role_arn}")
    print(f"ü™£ Using Bucket: {TERRAFORM_BUCKET}")

    pipeline = get_pipeline(
        region=os.environ.get("AWS_REGION", "eu-north-1"),
        role=role_arn,
        default_bucket=TERRAFORM_BUCKET
    )
    
    print(f"üìù Pipeline definition: {pipeline.name}")
    
    pipeline.upsert(role_arn=role_arn)
    print("‚úÖ Pipeline submitted/updated in SageMaker.")
    
    execution = pipeline.start()
    print(f"üèÉ Pipeline execution started. Execution ARN: {execution.arn}")